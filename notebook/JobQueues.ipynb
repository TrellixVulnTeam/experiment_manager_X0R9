{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Manager: Using Job Queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_arg_xp_man = '-e git+https://github.com/wschuell/experiment_manager.git@origin/master#egg=experiment_manager'\n",
    "#ssh: pip_arg_xp_man = '-e git+ssh://git@github.com/wschuell/experiment_manager.git@master#egg=experiment_manager'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import experiment_manager as xp_man\n",
    "except ImportError:\n",
    "    print('experiment_manager is not installed, you can install it with command: \\n pip install '+pip_arg_xp_man)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Queues\n",
    "Job Queues are one of the key classes of the library. You place jobs in them, and they run them and retrieve the data. You do not have to bother of where exactly things are run and how they are retrieved, everything is abstracted away and already adapted the specific clusters that we are using. In one line you can change clusters or execute it locally instead. Adapting it to a new cluster should take a really short time (~10 lines of code).\n",
    "\n",
    "#### Defining several job queue configs: local, multiprocess local, and several clusters. \n",
    "NB: <span style=\"color:red\">SSH usage: </span>To use plafrim, you <b>must have a working entry 'plafrim-ext'</b> in your .ssh/config. \n",
    "For the other clusters, if you don't have a corresponding entry (avakas or anyone), you should provide your username. You will then be asked your password and if you want to create a key and export it on the cluster to further automatize the connection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jq_cfg_local = {'jq_type':'local'}\n",
    "\n",
    "virtualenv = 'test_py3' # by default root python. ex: virtualenv = 'test_xp_man' for venv in ~/virtualenvs/test_xp_man\n",
    "\n",
    "jq_cfg_plafrim = {'jq_type':'plafrim',\n",
    "    'modules':['slurm','language/python/3.5.2'],\n",
    "    'virtual_env': virtualenv,\n",
    "    'requirements': [pip_arg_xp_man],\n",
    "    #'username':'schuelle',\n",
    "                 }\n",
    "\n",
    "jq_cfg_avakas = {'jq_type':'avakas',\n",
    "    'modules':['torque','maui','python3/3.6.0'],\n",
    "    'without_epilogue':True,\n",
    "    #'username':'wschueller',\n",
    "    'virtual_env':virtualenv,#virtualenv,\n",
    "    #'requirements': [pip_arg_xp_man],  IMPORTANT: install on avakas through github and https is broken due to the git version being too old. You have to install manually and via SSH...\n",
    "                }\n",
    "jq_cfg_curta = {'jq_type':'curta',\n",
    "    'modules':['slurm','python/3.7.2'],\n",
    "    'without_epilogue':True,\n",
    "    #'username':'wschueller',\n",
    "    'virtual_env':virtualenv,#virtualenv,\n",
    "    'requirements': [pip_arg_xp_man],  \n",
    "               }\n",
    "\n",
    "jq_cfg_anyone = {'jq_type':'anyone',\n",
    "    'modules':[],\n",
    "    'virtual_env':'test_279',\n",
    "    #'requirements': [pip_arg_xp_man],\n",
    "    \"hostname\":\"cluster_roma\"\n",
    "                }\n",
    "\n",
    "jq_cfg_docker = {'jq_type':'slurm',\n",
    "    'modules':[],\n",
    "    #'virtual_env':virtualenv,\n",
    "    #'requirements': [pip_arg_xp_man],\n",
    "     'ssh_cfg':{            \n",
    "     'username':'root',\n",
    "    'hostname':'172.19.0.2',\n",
    "    'password':'dockerslurm',}\n",
    "                }\n",
    "\n",
    "jq_cfg_local_multiprocess =  {'jq_type':'local_multiprocess',\n",
    "                              #'nb_process':4, #default value: number of CPUs on the local machine\n",
    "                             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The requirements section tells job queues to install a version of the library on the cluster if it does not exist yet. You can add other libraries, or add them for specific jobs. By default, virtual_env is set to None, meaning that everything runs and requirements are installed in the root python interpretor. If you provide a < name > for the value virtual_env attribute, it will search for a virtualenv in ~/virtualenvs/< name > .\n",
    "\n",
    "The pip_arg_xp_man refers here to the pip command necessary to install the library on the clusters, which is needed to run the jobs. You can use the same syntax to automatically update your own software to a given commit or branch of your own git repository.\n",
    "\n",
    "You can choose below which one of the job queue configuration you want to use. The job queue object is initialized under the variable name jq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jq_cfg = jq_cfg_curta\n",
    "jq = xp_man.job_queue.get_jobqueue(**jq_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019 05 06 01:08:11]: Queue updated\n",
      "    total: 0\n",
      "    \n",
      "\n",
      "    execution time: 0 s\n",
      "    jobs done: 0\n",
      "    jobs restarted: 0\n",
      "    jobs extended: 0\n",
      "\n",
      "    completion level of running jobs: 0.0%\n",
      "    minimum completion level: 0.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(jq.get_status_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jobs\n",
    "Jobs are the objects that need to be executed. Here we will use a simple type of job, ExampleJob. It goes through a loop of 24 steps, prints the value of the counter variable, waits a random time between 1 and 2 seconds between each steps, and at the end saves the value in a file < job.descr >data.dat\n",
    "\n",
    "Other types of jobs, and defining own classes of jobs as subclasses of the root Job class, will be explained in another notebook. However, there is a documented template provided with the library, found in experiment_manager/job/template_job.py\n",
    "\n",
    "We define job configurations, create the job objects, and add them to the job queue jq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_cfg = {\n",
    "    'estimated_time':120,#in seconds\n",
    "    #'virtual_env':'test',\n",
    "    #'requirements':[],\n",
    "    #...,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = xp_man.job.ExampleJob(**job_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019 05 06 01:08:12]: Queue updated\n",
      "    total: 1\n",
      "    pending: 1\n",
      "\n",
      "    execution time: 0 s\n",
      "    jobs done: 0\n",
      "    jobs restarted: 0\n",
      "    jobs extended: 0\n",
      "\n",
      "    completion level of running jobs: 0.0%\n",
      "    minimum completion level: 0.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jq.add_job(job) # of course, you can add as many jobs as you want, like in next cell\n",
    "print(jq.get_status_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019 05 06 01:08:13]: Queue updated\n",
      "    total: 21\n",
      "    pending: 21\n",
      "\n",
      "    execution time: 0 s\n",
      "    jobs done: 0\n",
      "    jobs restarted: 0\n",
      "    jobs extended: 0\n",
      "\n",
      "    completion level of running jobs: 0.0%\n",
      "    minimum completion level: 0.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    job_cfg_2 = { 'descr' : str(i),  'estimated_time':120,#a description for the example job \n",
    "    }\n",
    "    job = xp_man.job.ExampleJob(**job_cfg_2)\n",
    "    jq.add_job(job)\n",
    "print(jq.get_status_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step is to update the queue. One update will check the current status of each job attached to jq, and process its next step, being sending it to the cluster, retrieving it, unpacking it, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jq.ssh_session.reconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to open SSH session\n",
      "SSH session opened\n",
      "[2019 05 06 01:09:09]: Queue updated\n",
      "    total: 21\n",
      "    running: 21\n",
      "\n",
      "    execution time: 0 s\n",
      "    jobs done: 0\n",
      "    jobs restarted: 0\n",
      "    jobs extended: 0\n",
      "\n",
      "    completion level of running jobs: 0.0%\n",
      "    minimum completion level: 0.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jq.update_queue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can tell jq to automatically do updates until all jobs are done or in error status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019 05 06 01:10:22]: Queue updated\n",
      "    total: 0\n",
      "    \n",
      "\n",
      "    execution time: 12 min 49 s\n",
      "    jobs done: 21\n",
      "    jobs restarted: 0\n",
      "    jobs extended: 0\n",
      "\n",
      "    completion level of running jobs: 0.0%\n",
      "    minimum completion level: 0.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jq.auto_finish_queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
